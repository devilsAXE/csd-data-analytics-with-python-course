{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from preamble import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "### Classification and Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization, Overfitting, and Underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model_complexity](images/overfitting_underfitting_cartoon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In order to strike a balance between overfitting and underfitting, we need to find a sweet spot in the model complexity vs. accuray for training and generalization.</p>\n",
    "\n",
    "<p>On the other hand, we should be aware that large dataset size itself will lead to <b> bigger model complexity</b>, turning the sweet spot further right on the complexity spectrum.</p>\n",
    "\n",
    "<p>In the real world, you often have the ability to decide how much data to collect, which might be more beneficial than tweaking and tuning your model. Never underestimate the power of more data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relation of Model Complexity to Dataset Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Machine Learning Algorithms\n",
    "#### Some Sample Datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "mglearn.plots.plot_grid_search_overview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> <b>Generating Sample Dataset</b> using mglearn provided by authors </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "caption": "Forge dataset",
    "label": "forge_scatter"
   },
   "outputs": [],
   "source": [
    "# generate dataset\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "# plot dataset\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.legend([\"Class 0\", \"Class 1\"], loc=4)\n",
    "plt.xlabel(\"First feature\")\n",
    "plt.ylabel(\"Second feature\")\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "plt.plot(X, y, 'o')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Some real Datasets </p>\n",
    "    <h3> Cancer Dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys():\\n\", cancer.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of cancer data:\", cancer.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample counts per class:\\n\",\n",
    "      {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature names:\\n\", cancer.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Boston Housing Dataset </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(\"Data shape:\", boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "print(\"X.shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors\n",
    "##### k-Neighbors classification\n",
    "\n",
    "<p> The k-NN algorithm is arguably the simplest machine learning algorithm. Building the model consists only of storing the training dataset. To make a prediction for a new data point, the algorithm finds the closest data points in the training dataset—its “nearest neighbors.” </p>\n",
    "\n",
    "<p> The simplest version is to choose one closest point of a new unlabeled data to give the predicted target. This is 1-NN.</p>\n",
    "<p>\n",
    "For more completicated modelling, we can choose k nearest neighbors (i.e. k-NN) and conduct voting to determine the result. The voting involves counting the frequency of different label options for the k points and give the most frequent label to the new data point.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_classification(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Steps to apply kNN Model </h4>\n",
    "<p><b>Step 1 </b>: Split the data into Test and Train </p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Second</b> we instantiate a k-NN class and fit with our training set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Third</b> we make a prediction based on the test set (i.e. X_test)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set predictions:\", clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Fourth</b> we evaluate the accuracy of the model by comparing the predictions with “correct answers”.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set accuracy: {:.2f}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyzing KNeighborsClassifier\n",
    "\n",
    "<p>To further examine the effectiveness of k-NN models, we should check out the decision boundary of k-NN models on the same dataset but with different k values. Below we will check the visualizations of 1-NN to 9-NN.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # the fit method returns the object self, so we can instantiate\n",
    "    # and fit in one line\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(\"{} neighbor(s)\".format(n_neighbors))\n",
    "    ax.set_xlabel(\"feature 0\")\n",
    "    ax.set_ylabel(\"feature 1\")\n",
    "axes[0].legend(loc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> In the case of k-NN models, the more neighbors used, the simpler the model is (represented by the smoother boundry for higher k value above).</p>\n",
    "<h4> k-NN on Breast Cancer Dataset </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> From above graph we can observe that the accuracy on the test set is best around k=6.  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### k-neighbors regression\n",
    "<p>A k-neighbors regression model fetches the target value (continuous target variable) of the k nearest neighbors and calculate the mean of those target values as the predicted target value.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To use k-neighbors regression model, one should instantiate a KNeighborsRegressor class in scikit-learn. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "\n",
    "# split the wave dataset into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# instantiate the model and set the number of neighbors to consider to 3\n",
    "reg = KNeighborsRegressor(n_neighbors=3)\n",
    "# fit the model using the training data and training targets\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set predictions:\\n\", reg.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The .score() method for KNeighborsRegressor returns the R-square of the model, with 1 representing a perfect prediction and 0 representing a constant target value regardless of the feature values.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test set R^2: {:.2f}\".format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing KNeighborsRegressor\n",
    "<p>To visualize the changes in the model when k increases, we compare k-Neighbors Regressor model when k equals 1, 3, and 9.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "# create 1,000 data points, evenly spaced between -3 and 3\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1, 1)\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # make predictions using 1, 3, or 9 neighbors\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    ax.plot(line, reg.predict(line))\n",
    "    ax.plot(X_train, y_train, '^', c=mglearn.cm2(0), markersize=8)\n",
    "    ax.plot(X_test, y_test, 'v', c=mglearn.cm2(1), markersize=8)\n",
    "\n",
    "    ax.set_title(\n",
    "        \"{} neighbor(s)\\n train score: {:.2f} test score: {:.2f}\".format(\n",
    "            n_neighbors, reg.score(X_train, y_train),\n",
    "            reg.score(X_test, y_test)))\n",
    "    ax.set_xlabel(\"Feature\")\n",
    "    ax.set_ylabel(\"Target\")\n",
    "axes[0].legend([\"Model predictions\", \"Training data/target\",\n",
    "                \"Test data/target\"], loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The predicted line becomes significantly smoother when the count of neighbors increases. It signifies a reduction in complexity compared to 1-NR and 3-NR.\n",
    "</p>\n",
    "<p>\n",
    "We can then move forward to use similar methods to evaluate the “sweet spot” for k value in this model.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "X, y = mglearn.datasets.make_wave(n_samples=100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=608)\n",
    "# Create training and testing datasets\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 21)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # build the model\n",
    "    reg = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    reg.fit(X_train, y_train)\n",
    "    # record training accuracy\n",
    "    training_accuracy.append(reg.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(reg.score(X_test, y_test))\n",
    "\n",
    "plt.plot(neighbors_settings,\n",
    "         training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings,\n",
    "        test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We can observe from above graph that the increase of k result in a reduction in training accuracy. It is also interesting to see that the accuracy for test set increases significantly, to a point it even surpasses training set accuracy. It certainly seems that at the point where k equals around 10 we can see the best model setting for k-NR.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Strengths, weaknesses, and parameters\n",
    "\n",
    "<h5> Parameters of k-NN </h5>\n",
    "<p>In principle, there are two important parameters to the KNeighbors classifier: the number of neighbors and how you measure distance between data points. In practice, using a small number of neighbors like three or five often works well, but you should certainly adjust this parameter.</p>\n",
    "<h5> Pros </h5>\n",
    "<p>One of the strengths of k-NN is that the model is very easy to understand, and often gives reasonable performance without a lot of adjustments. Using this algorithm is a good baseline method to try before considering more advanced techniques.</p>\n",
    "<h5> Cons </h5>\n",
    "<p>Building the nearest neighbors model is usually very fast, but when your training set is very large (either in number of features or in number of samples) prediction can be slow.\n",
    "</p><p>This approach often does not perform well on datasets with many features (hundreds or more), and it does particularly badly with datasets where most features are 0 most of the time (so-called sparse datasets). Therefore this model is not good for practices such as text mining.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Models </h3>\n",
    "<h4>Linear models for regression</h4>\n",
    "\\begin{align*}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "    For regression, the general prediction formula for a linear model looks as follows:\n",
    "\n",
    "    ŷ = w[0] * x[0] + w[1] * x[1] + … + w[p] * x[p] + b\n",
    "\n",
    "    Here, x[0] to x[p] denotes the features (in this example, the number of features is p) of a single data point, w and b are parameters of the model that are learned, and ŷ is the prediction the model makes. For a dataset with a single feature, this is:\n",
    "\n",
    "    ŷ = w[0] * x[0] + b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For Linear Regression models, the bigger the absolute values of the coefficients, the more complex the model is. In other words, the flatter the linear line, the simpler the model is.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_regression_wave()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression aka ordinary least squares\n",
    "\n",
    "<p> Linear regression finds the parameters w and b that minimize the mean squared error between predictions and the true regression targets, y, on the training set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X, y = mglearn.datasets.make_wave(n_samples=60)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The fitted OLS model has two parameters, as below:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lr.coef_:\", lr.coef_)\n",
    "print(\"lr.intercept_:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> The model’s performance on training set and test set is as below: </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The linear regression’s performance on a simple dataset is not really impressive. </p>\n",
    "<h4>But we will now test it on a complex Boston Housing dataset.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Since OLS does not give options to control complexity, this model is overfitting. \n",
    "    <br/>We will then look at an alternative to OLS, which is<b> Ridge Regression</b>.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge regression\n",
    "<p>Ridge Regression is the basic OLS model plus the following restriction:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>We also want the magnitude of coefficients to be as small as possible; in other words, all entries of w should be close to zero.</li> <li>Intuitively, this means each feature should have as little effect on the outcome as possible (which translates to having a small slope), while still predicting well.</li></ul>\n",
    "\n",
    "This process, called <b>L2 regularization</b> helps to explicitly avoid overfitting.\n",
    "\n",
    "The sklearn uses Ridge class to instantiate Ridge Regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default parameter for Ridge model is alpha = 1.0. By changing the alpha value when instantiating the class, users can adjust the level of restrictions on the Ridge Regression.\n",
    "\n",
    "<h3>Higher Alpha -> Stronger restriction -> Parameter magnitude closer to zero</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge10 = Ridge(alpha=10).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge10.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge10.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge01 = Ridge(alpha=0.1).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(ridge01.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(ridge01.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# try alpha from 0.01 to 10\n",
    "alpha_settings = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
    "\n",
    "for alpha in alpha_settings:\n",
    "    # build the model\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    # record training accuracy\n",
    "    training_accuracy.append(ridge.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(ridge.score(X_test, y_test))\n",
    "\n",
    "plt.plot(np.log(np.array(alpha_settings)),\n",
    "         training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(np.log(np.array(alpha_settings)),\n",
    "        test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"alpha logs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from above graph, the performance of Ridge Regression model on the test set hits the highest point when the natural logarithm of the alpha is between -2 and -1. Considering the decreasing nature of the training accuracy, we should prefer an alpha within this range that is as low as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log alpha array: {}\".\n",
    "      format(np.around(np.log(np.array(alpha_settings)),3)))\n",
    "print(\"alpha array: {}\".format(np.array(alpha_settings)))\n",
    "\n",
    "print(\"Training performance: {:.5f}\".format(training_accuracy[3]))\n",
    "print(\"Test performance: {:.5f}\".format(test_accuracy[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the alpha arrays, we observe that the fourth alpha meets our conditions; i.e. when alpha = 0.2, we will see the optimized Ridge Model.\n",
    "\n",
    "<h3>Under the Hood for Ridge Regressions</h3>\n",
    "We can also get a more qualitative insight into how the alpha parameter changes the model by inspecting the coef_ attribute of models with different values of alpha. A higher alpha means a more restricted model, so we expect the entries of coef_ to have smaller magnitude for a high value of alpha than for a low value of alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ridge.coef_, 's', label=\"Ridge alpha=1\")\n",
    "plt.plot(ridge10.coef_, '^', label=\"Ridge alpha=10\")\n",
    "plt.plot(ridge01.coef_, 'v', label=\"Ridge alpha=0.1\")\n",
    "\n",
    "plt.plot(lr.coef_, 'o', label=\"LinearRegression\")\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-25, 25)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above graph we can see that with alpha larger, the coefficients are most condensed near the w=0 line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_ridge_n_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because ridge is regularized, the training score of ridge is lower than the training score for linear regression across the board. However, the test score for ridge is better, particularly for small subsets of the data. For less than 400 data points, linear regression is not able to learn anything. As more and more data becomes available to the model, both models improve, and linear regression catches up with ridge in the end.\n",
    "\n",
    "<h4>Key Takeaway</h4>\n",
    "\n",
    "With enough training data, regularization becomes less important, and given enough data, ridge and linear regression will have the same performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Lasso Regression </h2>\n",
    "\n",
    "Lasso Regression uses L1 Regularization to regularize the regression.\n",
    "\n",
    "The consequence of L1 regularization is that when using the lasso, some coefficients are exactly zero. This means some features are entirely ignored by the model. This can be seen as a form of automatic feature selection. Having some coefficients be exactly zero often makes a model easier to interpret, and can reveal the most important features of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently the default setting for this lasso regression is underfitting on the Housing dataset.\n",
    "\n",
    "Similarly, Lasso Regression also has alpha = 1.0 as its parameter. The larger alpha is, the simpler the model is.\n",
    "\n",
    "Another parameter, max_iter (maximum number of iterations to run) should also be defined. The smaller alpha is, the larger max_iter should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we increase the default setting of \"max_iter\",\n",
    "# otherwise the model would warn us that we should increase max_iter.\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso001.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted model ended up using 33 out of the 105 features in the dataset. This makes it potentially easier to understand.\n",
    "\n",
    "If we set alpha too low, the model will become too complicated and more similar to OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso00001 = Lasso(alpha=0.0001, max_iter=100000).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.2f}\".format(lasso00001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lasso00001.score(X_test, y_test)))\n",
    "print(\"Number of features used:\", np.sum(lasso00001.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# try alpha from 0.00001 to 10\n",
    "alpha_settings = [0.00001, 0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1, 2, 4, 8, 10]\n",
    "\n",
    "for alpha in alpha_settings:\n",
    "    # build the model\n",
    "    lasso = Lasso(alpha=alpha, max_iter=10000000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    # record training accuracy\n",
    "    training_accuracy.append(lasso.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(lasso.score(X_test, y_test))\n",
    "\n",
    "plt.plot(np.log(np.array(alpha_settings)),\n",
    "         training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(np.log(np.array(alpha_settings)),\n",
    "        test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"alpha logs\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the redge regression, the “sweet spot” for this specific case comes at -6 < log(alpha) < -4. We can check it out by looking at the corresponding arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"log alpha array: {}\".\n",
    "      format(np.around(np.log(np.array(alpha_settings)),3)))\n",
    "print(\"alpha array: {}\".format(np.array(alpha_settings)))\n",
    "\n",
    "print(\"Sweet spot alpha: {}\".format(alpha_settings[3]))\n",
    "print(\"Training performance: {:.5f}\".format(training_accuracy[3]))\n",
    "print(\"Test performance: {:.5f}\".format(test_accuracy[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Under the Hood for Lasso Regressions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lasso.coef_, 's', label=\"Lasso alpha=1\")\n",
    "plt.plot(lasso001.coef_, '^', label=\"Lasso alpha=0.01\")\n",
    "plt.plot(lasso00001.coef_, 'v', label=\"Lasso alpha=0.0001\")\n",
    "\n",
    "plt.plot(ridge01.coef_, 'o', label=\"Ridge alpha=0.1\")\n",
    "plt.legend(ncol=2, loc=(0, 1.05))\n",
    "plt.ylim(-25, 25)\n",
    "plt.xlabel(\"Coefficient index\")\n",
    "plt.ylabel(\"Coefficient magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, ridge regression is usually the first choice between these two models.\n",
    "\n",
    "However, if you have a large amount of features and expect only a few of them to be important, Lasso might be a better choice. Similarly, if you would like to have a model that is easy to interpret, Lasso will provide a model that is easier to understand, as it will select only a subset of the input features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Linear models for classification </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of Linear Models for classification, the predicted value threshold is set at zero (i.e. a logical determination of whether the target values meet the conditions or not).\n",
    "\n",
    "    Let’s look at binary classification first. In this case, a prediction is made using the following formula: \n",
    "    ŷ = w[0] * x[0] + w[1] * x[1] + … + w[p] * x[p] + b > 0\n",
    "\n",
    "The above formula, when reflected on chart, will appear to be a decision boundary that seperates two categories using a line, a plane, or a hyperplane.\n",
    "\n",
    "\n",
    "<h4>Common Models for Linear Classification</h4>\n",
    "\n",
    "All algorithms for linear classification models differ in the following two ways:\n",
    "\n",
    "    How models measure how well a particular combination of coefficients and intercept fits the training data\n",
    "    If any, what kind of regularization they use\n",
    "\n",
    "Two most common linear classification algorithms:\n",
    "\n",
    "    a. Logistic Regression: linear_model.LogisticRegression\n",
    "    b. Linear Support Vector Machines: svm.LinearSVC (Support Vector Classifier)\n",
    "\n",
    "Let’s see how these two algorithms apply on the forge dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "for model, ax in zip([LinearSVC(), LogisticRegression()], axes):\n",
    "    clf = model.fit(X, y)\n",
    "    mglearn.plots.plot_2d_separator(clf, X, fill=False, eps=0.5,\n",
    "                                    ax=ax, alpha=.7)\n",
    "    mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    "    ax.set_title(clf.__class__.__name__)\n",
    "    ax.set_xlabel(\"Feature 0\")\n",
    "    ax.set_ylabel(\"Feature 1\")\n",
    "axes[0].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above graphs, the line is the decision boundary that would determine the category of dots falling above or under the line. If the points fall above the line, they would be categorized as Category 1 and under as Category 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Tweaking the regularization parameters for LogisticRegression and LinearSVC</h4>\n",
    "\n",
    "<ul>\n",
    "   <li> By default, both models apply an L2 regularization, in the same way that Ridge does for regression.</li>\n",
    "    <li>For LogisticRegression and LinearSVC the trade-off parameter that determines the strength of the regularization is called C, and higher values of C correspond to less regularization. In other words, when you use a high value for the parameter C, LogisticRegression and LinearSVC try to fit the training set as best as possible, while with low values of the parameter C, the models put more emphasis on finding a coefficient vector (w) that is close to zero.</li>\n",
    "\n",
    "  <li>Using low values of C will cause the algorithms to try to adjust to the “majority” of data points, while using a higher value of C stresses the importance that each individual data point be classified correctly.</li>\n",
    "  </ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_linear_svc_regularization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left, the strongly regularized model choose a relatively horizontal line by following only the general trend: that category 1 points are above and category 0 points are below.\n",
    "\n",
    "On the right, since the regularization is been set to really low, the line tries its best to correctly categorize the points. Therefore, all points in category 0 is been identified.\n",
    "\n",
    "The right option might overfit since it is trying over hard to fit ALL OF THE POINTS in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Logistic Regression </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default value for C in LogisticRegression is 1. However, since the training and test sets have close scores, it is likely that the model is underfitting. Let’s try a more flexible model setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg100 = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg100.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg100.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more flexible (i.e. more complex) model have better performance in both training and test set. Just to compare the models, we can try a even more restricted model with C = 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg001 = LogisticRegression(C=0.01).fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg001.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg001.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, more restricted model results in lower performance and closer accuracy for both training and testing set. It’s time for us to examine again the performance-complexity graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# try C from 0.00001 to 1000\n",
    "C_settings = [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 1, 3, 5, 7, 10, 20, 30, 50, 70, 100]\n",
    "\n",
    "for C in C_settings:\n",
    "    # build the model\n",
    "    logreg = LogisticRegression(C=C)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    # record training accuracy\n",
    "    training_accuracy.append(logreg.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(logreg.score(X_test, y_test))\n",
    "\n",
    "plt.plot(np.array(C_settings),\n",
    "         training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(np.array(C_settings),\n",
    "        test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"C logs\")\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can expect from the C settings, having more and more flexible model makes the training accuracy more and more accurate; however, the accuracy of the data on the test set hits a plateau at around C = 5.\n",
    "\n",
    "Finally, let’s check out the coefficient combinations of the models at different levels of C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(logreg.coef_.T, 'o', label=\"C=1\")\n",
    "plt.plot(logreg100.coef_.T, '^', label=\"C=100\")\n",
    "plt.plot(logreg001.coef_.T, 'v', label=\"C=0.001\")\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, marker in zip([0.001, 1, 100], ['o', '^', 'v']):\n",
    "    lr_l1 = LogisticRegression(C=C, penalty=\"l1\").fit(X_train, y_train)\n",
    "    print(\"Training accuracy of l1 logreg with C={:.3f}: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_train, y_train)))\n",
    "    print(\"Test accuracy of l1 logreg with C={:.3f}: {:.2f}\".format(\n",
    "          C, lr_l1.score(X_test, y_test)))\n",
    "    plt.plot(lr_l1.coef_.T, marker, label=\"C={:.3f}\".format(C))\n",
    "\n",
    "plt.xticks(range(cancer.data.shape[1]), cancer.feature_names, rotation=90)\n",
    "xlims = plt.xlim()\n",
    "plt.hlines(0, xlims[0], xlims[1])\n",
    "plt.xlim(xlims)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Coefficient magnitude\")\n",
    "\n",
    "plt.ylim(-5, 5)\n",
    "plt.legend(loc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_animal_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_tree_progressive()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><ul>To build a tree, the algorithm searches over all possible tests and finds the one that is most  informative  about  the  target  variable.<li> First Figure, shows  the  first  test  that  is picked. Splitting the dataset horizontally at x[1]=0.0596 yields the most information;it  best  separates  the  points  in  class  0  from  the  points  in  class  1.</li>\n",
    "<li> The  top  node,  also called the root, represents the whole dataset, consisting of 75 points belonging to class0  and  75  points  belonging  to  class  1.</li> <li> The  split  is  done  by  testing  whether  x[1] = 0.0596, indicated by a black line. If the test is true, a point is assigned to the left node,which  contains  2  points  belonging  to  class  0  and  32  points  belonging  to  class  1.</li> <li>Otherwise the point is assigned to the right node, which contains 48 points belonging to class 0 and 18 points belonging to class 1. These two nodes correspond to the topand bottom regions shown in Figure.</li><li> Even though the first split did a good job of  separating  the  two  classes,  the  bottom  region  still  contains  points  belonging  toclass  0,  and  the  top  region  still  contains  points  belonging  to  class  1.</li> <li> We  can  build  a more  accurate  model  by  repeating  the  process  of  looking  for  the  best  test  in  bothregions.  Next Figure shows  that  the  most  informative  next  split  for  the  left  and  the right region is based on x[0].</li></ul></p>\n",
    "This  recursive  process  yields  a  binary  tree  of  decisions,  with  each  node  containing  a test.  Alternatively,  you  can  think  of  each  test  as  splitting  the  part  of  the  data  that  is currently  being  considered  along  one  axis.  This  yields  a  view  of  the  algorithm  as building  a  hierarchical  partition. \n",
    "As  each  test  concerns  only  a  single  feature,  the regions in the resulting partition always have axis-parallel boundaries.The  recursive  partitioning  of  the  data  is  repeated  until  each  region  in  the  partition(each  leaf  in  the  decision  tree)  only  contains  a  single  target  value  (a  single  class  or  a single regression value). A leaf of the tree that contains data points that all share the same  target  value  is  called  pure.  The  final  partitioning  for  this  dataset  is  shown  in last figure.\n",
    "\n",
    "A <b>prediction</b> on a new data point is made by checking which region of the partition of  the  feature  space  the  point  lies  in,  and  then  predicting  the  majority  target  (or  thesingle  target  in  the  case  of  pure  leaves)  in  that  region.  The  region  can  be  found  bytraversing  the  tree  from  the  root  and  going  left  or  right,  depending  on  whether  thetest is fulfilled or not.\n",
    "\n",
    "It  is  also  possible  to  use  trees  for <b> regression  tasks</b>,  using  exactly  the  same  technique.To  make  a  prediction,  we  traverse  the  tree  based  on  the  tests  in  each  node  and  findthe leaf the new data point falls into. The output for this data point is the mean targetof the training points in this leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Controlling complexity of decision trees</h3>\n",
    "\n",
    "Typically,  building  a  tree  as  described  here  and  continuing  until  all  leaves  are  pure leads  to  models  that  are <b> very  complex  and  highly  overfit </b> to  the  training  data.  \n",
    "\n",
    "The presence  of  pure  leaves  mean  that  a  tree  is  100%  accurate  on  the  training  set;  each data point in the training set is in a leaf that has the correct majority class. \n",
    "\n",
    "The over‐fitting  can  be  seen  on  the  left  of  previous last figure. \n",
    "\n",
    "There are two common strategies to prevent overfitting:\n",
    "<ul><li>Pre-Pruning: Stopping the creation of the tree early<i>(Possible  criteria  for  pre-pruning  include  limiting  the  maximum  depth  of  the  tree,limiting the maximum number of leaves, or requiring a minimum number of pointsin a node to keep splitting it), or</i></li>\n",
    "   <li>Post-Pruning : Building the tree but then removing or collapsing  nodes  that  contain  little  information</li>\n",
    "    </ul>\n",
    "    \n",
    "    \n",
    "Decision trees in scikit-learn are implemented in the <b>DecisionTreeRegressor</b> and <b>DecisionTreeClassifier  </b>classes.  scikit-learn  only  implements  pre-pruning,  not post-pruning.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "6e5d7a76-9bba-42f7-b26e-907775d289b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "tree = DecisionTreeClassifier(random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As  expected,  the  accuracy  on  the  training  set  is  100% because  the  leaves  are  pure,the tree was grown deep enough that it could perfectly memorize all the labels on the training  data.\n",
    "\n",
    "If  we  don’t  restrict  the  depth  of  a  decision  tree,  the  tree  can  become  arbitrarily  deep and complex. <b>Unpruned trees are therefore prone to overfitting </b> and not generalizing well to new data.\n",
    "\n",
    "Now let’s apply pre-pruning to the tree, which will stop developing the tree before we perfectly fit to the training data. One of the way is to restrict size of the tree. \n",
    "See, how it effects Training as well as Test Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=4, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzing Decision Trees\n",
    "\n",
    "We can visualize the tree using the export_graphviz function from the tree module.\n",
    "\n",
    "This writes a file in the .dot file format, which is a text file format for storing graphs.\n",
    "\n",
    "We set an option to color the nodes to reflect the majority class in each node and passthe class and features names so the tree can be properly labeled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(tree, out_file=\"tree.dot\", class_names=[\"malignant\", \"benign\"],\n",
    "                feature_names=cancer.feature_names, impurity=False, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "display(graphviz.Source(dot_graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance in trees\n",
    "\n",
    "Instead of looking at the whole tree, which can be taxing, there are some useful properties that we can derive to summarize the workings of the tree. \n",
    "\n",
    "The most commonly used  summary  is  feature  importance,  which  rates  how  important  each  feature  is  for the  decision  a  tree  makes. \n",
    "\n",
    "It  is  a  number  between  0  and  1  for  each  feature,  where  0 means  “not  used  at  all”  and  1  means  “perfectly  predicts  the  target.”  The  feature importances always sum to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "uuid": "dc2f68ee-0df0-47ed-b500-7ec99d5a0a5d"
   },
   "outputs": [],
   "source": [
    "print(\"Feature importances:\")\n",
    "print(tree.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the feature importances in a way that is similar to the way we visualize the coefficients in the linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances_cancer(model):\n",
    "    n_features = cancer.data.shape[1]\n",
    "    plt.barh(np.arange(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), cancer.feature_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.ylim(-1, n_features)\n",
    "\n",
    "plot_feature_importances_cancer(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However,  if  a  feature  has  a  low  value  in  feature_importance_,  it  doesn’t  mean  that this  feature  is  uninformative. \n",
    "\n",
    "It  only  means  that  the  feature  was  not  picked  by  the tree, likely because another feature encodes the same information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_metadata": {
   "author": "Andreas C. M\\\"ller",
   "title": "Machine Learning with Python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
